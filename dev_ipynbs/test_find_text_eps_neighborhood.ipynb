{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import PlaYnlp.tokenizer as tkr \n",
      "import PlaYnlp.vectorizer as vcr\n",
      "from PlaYnlp import dataio\n",
      "\n",
      "from PlaYnlp.sparse import L0_norm_col_summarizer as L0_col_sum\n",
      "from PlaYnlp.sparse import L1_norm_col_summarizer as L1_col_sum\n",
      "import numpy as np\n",
      "import scipy as sp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "jieba_without_html_tokenizer = tkr.tokenize_gen(lambda text:tkr.jieba.cut(tkr.nltk.clean_html(text)))\n",
      "unigram_without_html_tokenizer = tkr.tokenize_gen(lambda text:tkr.ngram(tkr.nltk.clean_html(text),n=1))\n",
      "bigram_without_html_tokenizer = tkr.tokenize_gen(lambda text:tkr.ngram(tkr.nltk.clean_html(text),n=2))\n",
      "jieba_vec_count_kwargs = {\"tokenizer\":jieba_without_html_tokenizer,\"lowercase\":False}\n",
      "unigram_vec_count_kwargs = {\"tokenizer\":unigram_without_html_tokenizer,\"lowercase\":False}\n",
      "bigram_vec_count_kwargs = {\"tokenizer\":bigram_without_html_tokenizer,\"lowercase\":False}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles_df,articles_push_df = dataio.read_pickle_file(\"PTT___movie.pickle\")\n",
      "test_ptt_text_sdtm = dataio.read_pickle_file(\"sdtm_ptt_movie.pickle\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test_ptt_text_sdtm = vcr.vectorize_text(df=articles_df,\n",
      "#                                          text_col=\"title\", \n",
      "#                                          vect_gen=vcr.CountVectorizer, \n",
      "#                                          vect_gen_init_kwargs = jieba_vec_count_kwargs,\n",
      "#                                          summarizer = L0_col_sum,\n",
      "#                                          dump_out_pickle = \"sdtm_ptt_movie.pickle\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_ptt_text_sdtm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "{'col_idx': array([u' ', u'!', u'\"', ..., u'\\uff3f', u'\\uff5c', u'\\uff5e'], \n",
        "       dtype='<U23'),\n",
        " 'row_idx': array([    0,     1,     2, ..., 26129, 26130, 26131]),\n",
        " 'smatrix': <26132x23366 sparse matrix of type '<type 'numpy.int64'>'\n",
        " \twith 288389 stored elements in Compressed Sparse Column format>,\n",
        " 'summarizer': <function PlaYnlp.sparse.L0_norm_col_summarizer>}"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "_unpickled_sdtm = test_ptt_text_sdtm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "one_news_idx = 4977\n",
      "one_news_sdtm = _unpickled_sdtm.select_rows([one_news_idx])\n",
      "print \"(one_news.summary > 0)._filtered_idx.shape = \",(one_news_sdtm.summary > 0)._filtered_idx.shape\n",
      "print \"// \".join(((one_news_sdtm.summary > 0))._filtered_idx)\n",
      "n_words = len((one_news_sdtm.summary > 0)._filtered_idx)\n",
      "print \"n_words = \",n_words\n",
      "filtered_words_sdtm = _unpickled_sdtm.select_columns(one_news_sdtm.summary > 0)\n",
      "\n",
      "words_weights = 1.0 / filtered_words_sdtm.summary._data\n",
      "print \"words_weights = \",words_weights\n",
      "words_weights*filtered_words_sdtm._smatrix.T\n",
      "\n",
      "n_top = 4\n",
      "select_post_ptrs = filtered_words_sdtm.summarize_sdf(lambda xx:words_weights*xx.T)._data.argsort()[-n_top:]\n",
      "print \"select_post_ptrs = \",select_post_ptrs\n",
      "\n",
      "\n",
      "print filtered_words_sdtm.summarize_sdf(lambda xx:words_weights*xx.T)._data[select_post_ptrs]\n",
      "\n",
      "# select_post_ptrs = filtered_words_sdtm.T.summary._data.argsort()[-n_top:]\n",
      "# print select_post_ptrs\n",
      "# filtered_words_sdtm = filtered_words_sdtm.select_rows(select_post_ptrs)\n",
      "# filtered_words_sdtm\n",
      "\n",
      "articles_df.ix[select_post_ptrs][\"title\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(one_news.summary > 0)._filtered_idx.shape =  (13,)\n",
        " // (// )// BBS// [// ]// \u5168\u9762// \u555f\u52d5// \u5716\u89e3// \u5de8\u96f7// \u7248// \u8aaa\u660e// \u9644\n",
        "n_words =  13\n",
        "words_weights =  [  4.21371987e-05   4.69043152e-04   4.80538203e-04   3.70370370e-02\n",
        "   3.91711387e-05   3.91696044e-05   7.87401575e-03   1.44927536e-02\n",
        "   2.50000000e-01   2.00000000e-01   8.40336134e-03   7.69230769e-02\n",
        "   2.00000000e-01]\n",
        "select_post_ptrs =  [ 4111  4138 20941  4977]\n",
        "[ 0.27248725  0.27252938  0.40107006  0.79588458]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "4111           [\u597d\u96f7] \u5716\u89e3\u5168\u9762\u555f\u52d5\u4e2d\u5922\u5883\u67b6\u69cb\n",
        "4138               [\u8a0e\u8ad6] \u5168\u9762\u555f\u52d5 \u5716\u89e3\n",
        "20941     [\u5de8\u96f7] \u96f7\u795e\u7d22\u723e\u89c0\u5f8c\u611f(\u5de8\u96f7\uff0c\u4e0d\u559c\u52ff\u5165)\n",
        "4977     [\u5de8\u96f7] \u5168\u9762\u555f\u52d5 \u5716\u89e3BBS\u7248 (\u9644\u8aaa\u660e)\n",
        "Name: title, dtype: object"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sdtm = test_ptt_text_sdtm\n",
      "init_group_idx = [4977,4138] #4138\n",
      "columns_filter = lambda xx:xx.summary>0\n",
      "n_tops = 4\n",
      "eps = 0.3\n",
      "\n",
      "\n",
      "# sdtm_proj_on_group_sdtm = sdtm.select_rows(init_group_idx)\n",
      "# filtered_words_sdtm = sdtm.select_columns(sdtm_proj_init_group.summary > 0)\n",
      "# within_wieghts = filtered_words_sdtm.select_rows(init_group_idx).summary._data\n",
      "# # within_wieghts = within_wieghts / float(within_wieghts.sum())\n",
      "# print \"within_wieghts = \",within_wieghts\n",
      "\n",
      "# all_weights = 1.0 / filtered_words_sdtm.summarize_sdf(L1_col_sum)._data\n",
      "# print \"all_weights = \",all_weights\n",
      "# words_weights = all_weights*within_wieghts\n",
      "# words_weights = words_weights / words_weights.sum()\n",
      "# print \"words_weights = \",words_weights\n",
      "\n",
      "# print \"// \".join(filtered_words_sdtm._col_idx)\n",
      "\n",
      "\n",
      "# sdtm_weighted_summary = filtered_words_sdtm.summarize_sdf(lambda xx:words_weights*xx.T)\n",
      "# selected_post_idx = (sdtm_weighted_summary > eps)._filtered_idx\n",
      "# selected_post_idx\n",
      "\n",
      "def find_similar_texts(sdtm, init_group_idx=[], eps=0.1):\n",
      "    print \"~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n",
      "    print \"init_group_idx = \",init_group_idx\n",
      "    sdtm_proj_on_group_sdtm = sdtm.select_rows(init_group_idx)\n",
      "    filtered_words_sdtm = sdtm.select_columns(sdtm_proj_on_group_sdtm.summary > 0)\n",
      "    within_wieghts = filtered_words_sdtm.select_rows(init_group_idx).summary._data\n",
      "    # within_wieghts = within_wieghts / float(within_wieghts.sum())\n",
      "#     print \"within_wieghts = \",within_wieghts\n",
      "\n",
      "    all_weights = 1.0 / filtered_words_sdtm.summarize_sdf(L1_col_sum)._data\n",
      "#     print \"all_weights = \",all_weights\n",
      "    words_weights = all_weights*within_wieghts\n",
      "    words_weights = words_weights / words_weights.sum()\n",
      "    print \"words_weights = \",words_weights\n",
      "\n",
      "    print \"// \".join(filtered_words_sdtm._col_idx)\n",
      "\n",
      "\n",
      "    sdtm_weighted_summary = filtered_words_sdtm.summarize_sdf(lambda xx:words_weights*xx.T)\n",
      "    selected_post_idx = (sdtm_weighted_summary > eps)._filtered_idx\n",
      "    \n",
      "    print \"selected_post_idx = \",selected_post_idx\n",
      "    print \"len(selected_post_idx) = \",len(selected_post_idx)\n",
      "    \n",
      "    return selected_post_idx\n",
      "\n",
      "\n",
      "def find_text_eps_neighborhood(sdtm, init_group_idx=[], eps=0.1):\n",
      "    \n",
      "    old_group_idx = init_group_idx\n",
      "    old_step_n_text = len(old_group_idx)\n",
      "    \n",
      "    \n",
      "    new_group_idx = find_similar_texts(sdtm = sdtm,\n",
      "                                       init_group_idx = old_group_idx,\n",
      "                                       eps = eps)\n",
      "    \n",
      "    new_step_n_text = len(new_group_idx)\n",
      "    \n",
      "    do_iteration = old_step_n_text != new_step_n_text\n",
      "    \n",
      "    n_iteration = 0\n",
      "    \n",
      "    while do_iteration:\n",
      "        \n",
      "        n_iteration = n_iteration + 1\n",
      "        print \"n_iteration = \",n_iteration\n",
      "        \n",
      "        old_group_idx = new_group_idx\n",
      "        old_step_n_text = len(old_group_idx)\n",
      "    \n",
      "    \n",
      "        new_group_idx = find_similar_texts(sdtm = sdtm,\n",
      "                                           init_group_idx = old_group_idx,\n",
      "                                           eps = eps)\n",
      "    \n",
      "        new_step_n_text = len(new_group_idx)\n",
      "    \n",
      "        do_iteration = old_step_n_text != new_step_n_text\n",
      "        \n",
      "    return new_group_idx\n",
      "        \n",
      "    \n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# filtered_words_sdtm\n",
      "# n_words = len(filtered_words_sdtm._col_idx)\n",
      "# print \"n_words = \",n_words\n",
      "\n",
      "# words_weights = 1.0 / (filtered_words_sdtm.summary._data**2)\n",
      "# words_weights = words_weights / words_weights.sum()\n",
      "# print \"words_weights = \",words_weights\n",
      "# sdtm_weighted_summary = filtered_words_sdtm.summarize_sdf(lambda xx:words_weights*xx.T)\n",
      "# selected_post_idx = (sdtm_weighted_summary > eps)._filtered_idx\n",
      "# selected_post_idx\n",
      "\n",
      "# articles_df.ix[selected_post_idx][\"title\"]\n",
      "\n",
      "# selected_post_ptrs = filtered_words_sdtm.summarize_sdf(lambda xx:words_weights*xx.T)._data.argsort()[-n_tops:]\n",
      "# selected_post_idx = filtered_words_sdtm.summarize_sdf(lambda xx:words_weights*xx.T)._idx[selected_post_ptrs]\n",
      "\n",
      "# print filtered_words_sdtm.summarize_sdf(lambda xx:words_weights*xx.T)._data[selected_post_ptrs]\n",
      "\n",
      "\n",
      "\n",
      "# def simple_text_clustering(sdtm, init_group_idx=[], col_filter=columns_filter, eps=0.3, n_top_words=20):\n",
      "#     print \"~~~~~~~~~~~~~~~~~~\"\n",
      "#     print \"init_group_idx = \",init_group_idx\n",
      "#     sdtm_proj_init_group = sdtm.select_rows(init_group_idx)\n",
      "#     filtered_words_sdtm = sdtm.select_columns(columns_filter(sdtm_proj_init_group))\n",
      "#     n_words = len(filtered_words_sdtm._col_idx)\n",
      "#     print \"n_words = \",n_words\n",
      "    \n",
      "#     while n_words>n_top_words:\n",
      "#         words_weights = 1.0 / (filtered_words_sdtm.summary._data)\n",
      "#         print \"words_weights = \",words_weights\n",
      "#         n_top_words_ptrs = words_weights.argsort()[-n_top_words:]\n",
      "        \n",
      "#         filtered_words_sdtm = filtered_words_sdtm.select_columns(n_top_words_ptrs)\n",
      "#         n_words = len(filtered_words_sdtm._col_idx)\n",
      "#         print \"n_words = \",n_words\n",
      "        \n",
      "        \n",
      "    \n",
      "#     print \"// \".join(filtered_words_sdtm._col_idx)\n",
      "    \n",
      "#     words_weights = 1.0 / (filtered_words_sdtm.summary._data)\n",
      "#     print \"words_weights = \",words_weights\n",
      "#     words_weights = words_weights / words_weights.sum()\n",
      "#     print \"words_weights = \",words_weights\n",
      "#     sdtm_weighted_summary = filtered_words_sdtm.summarize_sdf(lambda xx:words_weights*xx.T)\n",
      "#     print sdtm_weighted_summary._data\n",
      "#     selected_post_idx = (sdtm_weighted_summary > eps)._filtered_idx\n",
      "#     print \"selected_post_idx = \",selected_post_idx\n",
      "    \n",
      "#     print articles_df.ix[selected_post_idx][\"title\"]\n",
      "    \n",
      "#     return selected_post_idx\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r1 = find_similar_texts(test_ptt_text_sdtm, [2700])  # 2500,2900\n",
      "r2 = find_similar_texts(test_ptt_text_sdtm, r1)\n",
      "r3 = find_similar_texts(test_ptt_text_sdtm, r2)\n",
      "\n",
      "print \"~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n",
      "print articles_df.ix[r1][\"title\"]\n",
      "print \"~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n",
      "print articles_df.ix[r3][\"title\"]\n",
      "print \"~~~~~~~~~~~~~~~~~~~~~~~~~~~\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "init_group_idx =  [2700]\n",
        "words_weights =  [  2.12065022e-05   3.14278960e-05   3.14278960e-05   1.02051265e-03\n",
        "   1.02051265e-03   1.04834482e-02   1.56045913e-04   8.07225508e-02\n",
        "   5.76589649e-02   8.07225508e-01   4.03612754e-02   7.52307090e-04\n",
        "   5.14812186e-04]\n",
        " // [// ]// \u3010// \u3011// \u537b// \u597d\u96f7// \u5f37\u5927// \u6548\u61c9// \u8106\u5f31\u4e0d\u582a// \u9707\u64bc// \uff0c// \uff1a\n",
        "selected_post_idx =  [2700]\n",
        "len(selected_post_idx) =  1\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "init_group_idx =  [2700]\n",
        "words_weights =  [  2.12065022e-05   3.14278960e-05   3.14278960e-05   1.02051265e-03\n",
        "   1.02051265e-03   1.04834482e-02   1.56045913e-04   8.07225508e-02\n",
        "   5.76589649e-02   8.07225508e-01   4.03612754e-02   7.52307090e-04\n",
        "   5.14812186e-04]\n",
        " // [// ]// \u3010// \u3011// \u537b// \u597d\u96f7// \u5f37\u5927// \u6548\u61c9// \u8106\u5f31\u4e0d\u582a// \u9707\u64bc// \uff0c// \uff1a\n",
        "selected_post_idx =  [2700]\n",
        "len(selected_post_idx) =  1\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "init_group_idx =  [2700]\n",
        "words_weights = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [  2.12065022e-05   3.14278960e-05   3.14278960e-05   1.02051265e-03\n",
        "   1.02051265e-03   1.04834482e-02   1.56045913e-04   8.07225508e-02\n",
        "   5.76589649e-02   8.07225508e-01   4.03612754e-02   7.52307090e-04\n",
        "   5.14812186e-04]\n",
        " // [// ]// \u3010// \u3011// \u537b// \u597d\u96f7// \u5f37\u5927// \u6548\u61c9// \u8106\u5f31\u4e0d\u582a// \u9707\u64bc// \uff0c// \uff1a\n",
        "selected_post_idx =  [2700]\n",
        "len(selected_post_idx) =  1\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "2700    [\u597d\u96f7] \u3010\u9707\u64bc\u6548\u61c9\u3011\uff1a\u5f37\u5927\uff0c\u537b\u8106\u5f31\u4e0d\u582a\n",
        "Name: title, dtype: object\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "2700    [\u597d\u96f7] \u3010\u9707\u64bc\u6548\u61c9\u3011\uff1a\u5f37\u5927\uff0c\u537b\u8106\u5f31\u4e0d\u582a\n",
        "Name: title, dtype: object\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "find_text_eps_neighborhood(test_ptt_text_sdtm, [2500], 0.3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "init_group_idx =  [2500]\n",
        "words_weights =  [  1.12714316e-04   1.98265732e-03   2.03243507e-03   1.67041870e-04\n",
        "   1.67041870e-04   3.90042767e-02   7.98970287e-03   8.25090469e-02\n",
        "   1.89843825e-02   5.99227715e-03   7.15078407e-01   8.75606213e-02\n",
        "   4.64135703e-04   3.66706875e-02   1.28457199e-03]\n",
        " // (// )// [// ]// \u4e0b// \u5728// \u597d\u7247// \u63a8\u85a6// \u6709\u96f7// \u674e\u9023\u6770// \u6f14\u51fa// \u7684// \u7d93\u5178// \u8a0e\u8ad6\n",
        "selected_post_idx =  [ 2500  4074  4344  7663  8829 17082]\n",
        "len(selected_post_idx) =  6\n",
        "n_iteration =  1\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "init_group_idx =  [ 2500  4074  4344  7663  8829 17082]\n",
        "words_weights =  [  2.40270898e-05   8.45278349e-05   8.66500402e-05   3.09506319e-04\n",
        "   4.27295857e-05   4.27295857e-05   4.24404257e-04   6.91562324e-05\n",
        "   6.93397403e-05   6.52502621e-04   6.64351942e-04   1.66289304e-03\n",
        "   2.81412669e-02   1.46334588e-03   1.81107163e-03   4.46142036e-03\n",
        "   7.03531672e-03   6.60354638e-04   4.35519607e-03   3.40629860e-04\n",
        "   3.51765836e-03   3.65836470e-02   6.53279410e-03   3.08462453e-04\n",
        "   1.82918235e-02   8.09372720e-04   9.62727551e-03   1.28815658e-04\n",
        "   1.82918235e-01   2.55472395e-04   1.82918235e-01   4.15723261e-03\n",
        "   1.82918235e-01   6.30752534e-03   2.77148841e-03   2.12695622e-03\n",
        "   3.73302520e-03   8.31446522e-03   3.95755592e-05   1.82918235e-01\n",
        "   1.66289304e-02   3.12680743e-03   5.47659386e-05   9.14591174e-02\n",
        "   1.15042915e-03]\n",
        " // (// )// 3// [// ]// \u3001// \u300a// \u300b// \u300c// \u300d// \u4e0b// \u4e0d\u4e8c// \u4efb\u52d9// \u518d// \u51fa\u7210// \u529f\u592b// \u548c// \u559c\u5287// \u5728// \u597d\u7247// \u5c55// \u5fb5\u6587// \u60c5\u5831// \u6311// \u63a8\u85a6// \u6587\u7ae0// \u65b0\u805e// \u65b9\u4e16\u7389// \u6709\u96f7// \u674e\u9023\u6770// \u6b63\u5f0f// \u6b78\u968a// \u6d74\u8840// \u6d77\u5831// \u6f14// \u6f14\u51fa// \u7504\u5b50\u4e39// \u7684// \u7687\u5e1d// \u795e\u63a2// \u7d93\u5178// \u8a0e\u8ad6// \u8eab\u624b// \u9592\u804a\n",
        "selected_post_idx =  [ 4344  8829 17082]\n",
        "len(selected_post_idx) =  3\n",
        "n_iteration =  2\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "init_group_idx =  [ 4344  8829 17082]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "words_weights =  [  1.69804672e-05   3.64558085e-04   2.51649400e-05   2.51649400e-05\n",
        "   8.14570239e-05   8.16731721e-05   5.12375334e-04   5.21679971e-04\n",
        "   1.65733714e-02   1.72363062e-03   2.13320622e-03   5.25497142e-03\n",
        "   8.28668570e-03   2.56492653e-03   4.30907656e-02   7.69477958e-03\n",
        "   3.63328547e-04   2.15453828e-02   7.58640240e-05   2.15453828e-01\n",
        "   1.07726914e-01   4.89667791e-03   2.15453828e-01   7.42944235e-03\n",
        "   3.26445194e-03   2.33074241e-05   2.15453828e-01   9.79335582e-03\n",
        "   1.84148571e-03   1.07726914e-01]\n",
        " // 3// [// ]// \u300a// \u300b// \u300c// \u300d// \u4e0d\u4e8c// \u4efb\u52d9// \u518d// \u51fa\u7210// \u529f\u592b// \u559c\u5287// \u5c55// \u5fb5\u6587// \u60c5\u5831// \u6311// \u65b0\u805e// \u65b9\u4e16\u7389// \u674e\u9023\u6770// \u6b63\u5f0f// \u6b78\u968a// \u6d74\u8840// \u6d77\u5831// \u7684// \u7687\u5e1d// \u795e\u63a2// \u7d93\u5178// \u8eab\u624b\n",
        "selected_post_idx =  [ 4344 17082]\n",
        "len(selected_post_idx) =  2\n",
        "n_iteration =  3\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "init_group_idx =  [ 4344 17082]\n",
        "words_weights =  [  1.46524609e-05   4.71866264e-04   2.17148501e-05   2.17148501e-05\n",
        "   1.05434012e-04   1.05713784e-04   3.31596863e-04   3.37618598e-04\n",
        "   2.23098370e-03   2.76111844e-03   1.07258832e-02   3.31991622e-03\n",
        "   9.95974865e-03   2.78872962e-02   9.81947050e-05   2.78872962e-01\n",
        "   9.29576541e-02   2.78872962e-01   9.61630904e-03   3.01679968e-05\n",
        "   2.78872962e-01   2.38352959e-03]\n",
        " // 3// [// ]// \u300a// \u300b// \u300c// \u300d// \u4efb\u52d9// \u518d// \u529f\u592b// \u559c\u5287// \u5fb5\u6587// \u6311// \u65b0\u805e// \u65b9\u4e16\u7389// \u674e\u9023\u6770// \u6b78\u968a// \u6d74\u8840// \u7684// \u7687\u5e1d// \u7d93\u5178\n",
        "selected_post_idx =  [ 4344 17082]\n",
        "len(selected_post_idx) =  2\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "array([ 4344, 17082])"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Reference:\n",
      "\n",
      "- ## [dbscan](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/cluster/dbscan_.py)\n",
      "- ## [utils:check_random_state](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/__init__.py)\n",
      "- ## [validation:check_random_state](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/validation.py)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from sklearn.utils import check_random_state"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# random_state=None\n",
      "\n",
      "# n = test_ptt_text_sdtm._smatrix.shape[0]\n",
      "# index_order = np.arange(n)\n",
      "# random_state = check_random_state(random_state)\n",
      "# random_state.shuffle(index_order)\n",
      "# print \"index_order = \",index_order\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# neighborhoods = []\n",
      "# labels = -np.ones(n, dtype=np.int)\n",
      "\n",
      "# # A list of all core samples found.\n",
      "# core_samples = []\n",
      "\n",
      "# # label_num is the label given to the new cluster\n",
      "# label_num = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# labels[305] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# for index in index_order[:100]:\n",
      "#     print \"~~~~~~~~~~~~~\"\n",
      "#     print \"index = \",index\n",
      "#     # Already classified\n",
      "#     if labels[index] != -1:\n",
      "#         print \"labels[index] = \",labels[index]\n",
      "#         continue"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    }
   ],
   "metadata": {}
  }
 ]
}