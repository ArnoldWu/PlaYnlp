{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import PlaYnlp.tokenizer as tkr \n",
      "import PlaYnlp.vectorizer as vcr\n",
      "from PlaYnlp import dataio\n",
      "\n",
      "from PlaYnlp.sparse import L0_norm_col_summarizer as L0_col_sum\n",
      "from PlaYnlp.sparse import L1_norm_col_summarizer as L1_col_sum\n",
      "import numpy as np\n",
      "import scipy as sp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "jieba_without_html_tokenizer = tkr.tokenize_gen(lambda text:tkr.jieba.cut(tkr.nltk.clean_html(text)))\n",
      "unigram_without_html_tokenizer = tkr.tokenize_gen(lambda text:tkr.ngram(tkr.nltk.clean_html(text),n=1))\n",
      "bigram_without_html_tokenizer = tkr.tokenize_gen(lambda text:tkr.ngram(tkr.nltk.clean_html(text),n=2))\n",
      "jieba_vec_count_kwargs = {\"tokenizer\":jieba_without_html_tokenizer,\"lowercase\":False}\n",
      "unigram_vec_count_kwargs = {\"tokenizer\":unigram_without_html_tokenizer,\"lowercase\":False}\n",
      "bigram_vec_count_kwargs = {\"tokenizer\":bigram_without_html_tokenizer,\"lowercase\":False}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# articles_df,articles_push_df = dataio.read_pickle_file(\"PTT___movie.pickle\")\n",
      "# test_ptt_text_sdtm = dataio.read_pickle_file(\"sdtm_ptt_movie.pickle\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd \n",
      "test_text_df = pd.DataFrame([u\"\u4eca\u5929\u5929\u6c23\u5f88\u597d\",u\"\u4eca\u5929\u5929\u6c23\u5f88\u721b\",u\"\u6211\u6068\u5b83\",u\"\u5b83\u6068\u6211\",u\"\u6211\u611b\u5b83\",u\"\u5b83\u611b\u6211\",u\"\u4eca\u5929\u5f88\u8870\",\"\u65e5\u5b50\u4e00\u5929\u4e00\u5929\u904e\",\"\u5929\u5929\u5237\u7259\u6d17\u81c9\"])\n",
      "test_text_df.columns = [\"text\"]\n",
      "test_text_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>text</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  \u4eca\u5929\u5929\u6c23\u5f88\u597d</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>  \u4eca\u5929\u5929\u6c23\u5f88\u721b</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>     \u6211\u6068\u5b83</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>     \u5b83\u6068\u6211</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>     \u6211\u611b\u5b83</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>     \u5b83\u611b\u6211</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td>    \u4eca\u5929\u5f88\u8870</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td> \u65e5\u5b50\u4e00\u5929\u4e00\u5929\u904e</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td>  \u5929\u5929\u5237\u7259\u6d17\u81c9</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>9 rows \u00d7 1 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "      text\n",
        "0   \u4eca\u5929\u5929\u6c23\u5f88\u597d\n",
        "1   \u4eca\u5929\u5929\u6c23\u5f88\u721b\n",
        "2      \u6211\u6068\u5b83\n",
        "3      \u5b83\u6068\u6211\n",
        "4      \u6211\u611b\u5b83\n",
        "5      \u5b83\u611b\u6211\n",
        "6     \u4eca\u5929\u5f88\u8870\n",
        "7  \u65e5\u5b50\u4e00\u5929\u4e00\u5929\u904e\n",
        "8   \u5929\u5929\u5237\u7259\u6d17\u81c9\n",
        "\n",
        "[9 rows x 1 columns]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_jieba_sdtm = vcr.vectorize_text(df=test_text_df,\n",
      "                                     text_col=\"text\", \n",
      "                                     idx_col=None, \n",
      "                                     cond_query={},\n",
      "                                     idx_query= [],\n",
      "                                     vect_gen=vcr.CountVectorizer, \n",
      "                                     vect_gen_init_kwargs = unigram_vec_count_kwargs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"// \".join(test_jieba_sdtm._col_idx)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u4e00// \u4eca// \u5237// \u5929// \u597d// \u5b50// \u5b83// \u5f88// \u6068// \u611b// \u6211// \u65e5// \u6c23// \u6d17// \u721b// \u7259// \u81c9// \u8870// \u904e\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "import numpy as np\n",
      "from PlaYnlp.dataio import write_pickle_file\n",
      "\n",
      "\n",
      "#L1_norm_col_summarizer = lambda xx:np.abs(xx).sum(axis=0)\n",
      "#L0_norm_col_summarizer = lambda xx:xx.sign().sum(axis=0)\n",
      "\n",
      "def L1_norm_col_summarizer(xx):\n",
      "    return np.abs(xx).sum(axis=0)\n",
      "\n",
      "def L0_norm_col_summarizer(xx):\n",
      "    return xx.sign().sum(axis=0)\n",
      "    \n",
      "\n",
      "\n",
      "class SparseDataFrameSummary(dict):\n",
      "    _key_mapper = {\"data\":\"summary_data\",\n",
      "                   \"idx\":\"summary_idx\",}\n",
      "    \n",
      "    def __init__(self, summary_data, summary_idx, sdf=None, **kwargs):\n",
      "        self[\"summary_data\"] = summary_data\n",
      "        self[\"summary_idx\"] = summary_idx\n",
      "        \n",
      "        if sdf != None:\n",
      "            self[\"sdf\"] = sdf\n",
      "            if self[\"sdf\"].is_matched_col_shape(self['summary_data']):        \n",
      "                self[\"summary_type\"] = \"col\"\n",
      "        \n",
      "            if self[\"sdf\"].is_matched_row_shape(self['summary_data']):     \n",
      "                self[\"summary_type\"] = \"row\"\n",
      "    \n",
      "        self.update(kwargs)\n",
      "        \n",
      "        \n",
      "    def __getstate__(self):\n",
      "        pass\n",
      "    \n",
      "     \n",
      "    def __setstate__(self, state):\n",
      "        pass\n",
      "    \n",
      "             \n",
      "    def __getattr__(self, key):\n",
      "        \n",
      "        if key.startswith(\"_\") and key[1:] in self.keys():\n",
      "            return self[key[1:]]\n",
      "        else:\n",
      "            \n",
      "            if key.startswith(\"_\") and key[1:] in self._key_mapper.keys() and self._key_mapper[key[1:]] in self.keys():\n",
      "                return self[self._key_mapper[key[1:]]]\n",
      "            else:\n",
      "                return None\n",
      "            \n",
      "        \n",
      "    def __lt__(self, upper_bound):\n",
      "        return type(self)(summary_data = self[\"summary_data\"] < upper_bound,\n",
      "                          summary_idx = self[\"summary_idx\"],\n",
      "                          sdf = self[\"sdf\"])\n",
      "    \n",
      "    \n",
      "    def __le__(self, upper_bound):\n",
      "        return type(self)(summary_data = self[\"summary_data\"] <= upper_bound,\n",
      "                          summary_idx = self[\"summary_idx\"],\n",
      "                          sdf = self[\"sdf\"])\n",
      "    \n",
      "    \n",
      "    def __gt__(self, lower_bound):\n",
      "        return type(self)(summary_data = self[\"summary_data\"] > lower_bound,\n",
      "                          summary_idx = self[\"summary_idx\"],\n",
      "                          sdf = self[\"sdf\"])\n",
      "        \n",
      "        \n",
      "    def __ge__(self, lower_bound):\n",
      "        return type(self)(summary_data = self[\"summary_data\"] > lower_bound,\n",
      "                              summary_idx = self[\"summary_idx\"],\n",
      "                              sdf = self[\"sdf\"])\n",
      "    \n",
      "    \n",
      "    def __and__(self, other_summary):\n",
      "        assert isinstance(other_summary, type(self))\n",
      "        assert np.array_equal(self[\"summary_idx\"],other_summary[\"summary_idx\"])\n",
      "        assert self['summary_data'].dtype == np.bool\n",
      "        assert other_summary['summary_data'].dtype == np.bool\n",
      "        \n",
      "        return type(self)(summary_data = self[\"summary_data\"] &  other_summary['summary_data'],\n",
      "                          summary_idx = self[\"summary_idx\"],\n",
      "                          sdf = self[\"sdf\"])\n",
      "        \n",
      "    @property\n",
      "    def _is_bool(self):\n",
      "        return self['summary_data'].dtype == np.bool\n",
      "    \n",
      "#    @property\n",
      "#    def _is_sortable(self):\n",
      "#        return isinstance(self['summary_data'].dtype, (np.int, np.float))\n",
      "    \n",
      "    @property\n",
      "    def _has_sdf(self):\n",
      "        return \"sdf\" in self.keys()\n",
      "    \n",
      "    @property\n",
      "    def _filtered_idx(self):\n",
      "        assert self._is_bool\n",
      "        \n",
      "        return self[\"summary_idx\"][self['summary_data']]\n",
      "    \n",
      "    @property\n",
      "    def _filtered_ptrs(self):\n",
      "        assert self._is_bool\n",
      "        \n",
      "        _ptr = np.nonzero(self['summary_data'])\n",
      "\n",
      "        if len(_ptr) == 1:\n",
      "            _ptr = _ptr[0]\n",
      "            \n",
      "        return _ptr\n",
      "    \n",
      "    @property\n",
      "    def _summary_type(self):\n",
      "        assert self._has_sdf\n",
      "        return self[\"summary_type\"]\n",
      "    \n",
      "    \n",
      "    @property\n",
      "    def _sub_sdf(self):\n",
      "        assert self._is_bool and self._has_sdf\n",
      "        \n",
      "        if self[\"sdf\"].is_matched_col_shape(self['summary_data']):        \n",
      "            return self[\"sdf\"].select_columns(select_col = self['summary_data'])\n",
      "        \n",
      "        if self[\"sdf\"].is_matched_row_shape(self['summary_data']):        \n",
      "            return self[\"sdf\"].select_rows(select_row = self['summary_data'])\n",
      "        \n",
      "    @property\n",
      "    def _argsort_ptrs(self):\n",
      "#        assert self._is_sortable\n",
      "        return self._data.argsort()\n",
      "        \n",
      "    def top_k_ptrs(self, k=20, reverse=False):\n",
      "        if reverse:\n",
      "            return self._argsort_ptrs[:k]\n",
      "        else:\n",
      "            return self._argsort_ptrs[-k:]\n",
      "\n",
      "    def top_k_idx(self, k=20, reverse=False):\n",
      "        return self._idx[self.top_k_ptrs(k,reverse)]\n",
      "    \n",
      "    \n",
      "class SparseDataFrame(dict):\n",
      "    _key_mapper = {}\n",
      "    _summerizer_class = SparseDataFrameSummary\n",
      "    _dump_file_prefix = \"sdf\"\n",
      "    \n",
      "    def __init__(self, smatrix, col_idx=None, row_idx=None, summarizer=None):\n",
      "        self[\"smatrix\"] = smatrix\n",
      "        \n",
      "        if col_idx != None:\n",
      "            assert isinstance(col_idx, (list, np.ndarray))\n",
      "            \n",
      "            if isinstance(col_idx, list):\n",
      "                assert self[\"smatrix\"].shape[1] == len(col_idx)\n",
      "                self[\"col_idx\"] = np.array(col_idx)\n",
      "                \n",
      "            else:\n",
      "                assert self[\"smatrix\"].shape[1] == col_idx.shape[0]\n",
      "                self[\"col_idx\"] = np.array(col_idx)\n",
      "        else:\n",
      "            self[\"col_idx\"] = np.arange(self[\"smatrix\"].shape[1])\n",
      "            \n",
      "                        \n",
      "        if row_idx != None:\n",
      "            assert isinstance(row_idx, (list, np.ndarray))\n",
      "            \n",
      "            if isinstance(row_idx, list):\n",
      "                assert self[\"smatrix\"].shape[0] == len(row_idx)\n",
      "                self[\"row_idx\"] = np.array(row_idx)\n",
      "                \n",
      "            else:\n",
      "                assert self[\"smatrix\"].shape[0] == row_idx.shape[0]\n",
      "                self[\"row_idx\"] = np.array(row_idx)\n",
      "                \n",
      "        else:\n",
      "            self[\"row_idx\"] = np.arange(self[\"smatrix\"].shape[0])\n",
      "            \n",
      "        \n",
      "        if summarizer != None and callable(summarizer):\n",
      "            self[\"summarizer\"] = summarizer\n",
      "            \n",
      "    \n",
      "    def __getstate__(self):\n",
      "        pass\n",
      "    \n",
      "     \n",
      "    def __setstate__(self, state):\n",
      "        pass\n",
      "    \n",
      "    \n",
      "    def __getattr__(self, key):\n",
      "        \n",
      "        if key.startswith(\"_\") and key[1:] in self.keys():\n",
      "            return self[key[1:]]\n",
      "        else:\n",
      "            \n",
      "            if key.startswith(\"_\") and key[1:] in self._key_mapper.keys() and self._key_mapper[key[1:]] in self.keys():\n",
      "                return self[self._key_mapper[key[1:]]]\n",
      "            else:\n",
      "                return None\n",
      "\n",
      "        \n",
      "#     @property\n",
      "#     def _smatrix(self):\n",
      "#         return self[\"smatrix\"]\n",
      "    \n",
      "#     @property\n",
      "#     def _col_idx(self):\n",
      "#         return self[\"col_idx\"]\n",
      "    \n",
      "#     @property\n",
      "#     def _row_idx(self):\n",
      "#         return self[\"row_idx\"]\n",
      "\n",
      "\n",
      "    @property\n",
      "    def T(self):\n",
      "        tr_sdf = type(self)(smatrix = self[\"smatrix\"].T,\n",
      "                            col_idx = self[\"row_idx\"],\n",
      "                            row_idx = self[\"col_idx\"],\n",
      "                            summarizer = self[\"summarizer\"] if self._has_default_summarizer else None)\n",
      "        return tr_sdf\n",
      "    \n",
      "    \n",
      "    @property\n",
      "    def _has_default_summarizer(self):\n",
      "        return \"summarizer\" in self.keys()\n",
      "    \n",
      "    \n",
      "    @property\n",
      "    def summary(self):\n",
      "        if self._has_default_summarizer:\n",
      "            return self.summarize_sdf(summarizer = self[\"summarizer\"]) \n",
      "            \n",
      "    \n",
      "    def change_default_summerizer(self, summarizer=None):\n",
      "        if summarizer != None and callable(summarizer):\n",
      "            self[\"summarizer\"] = summarizer\n",
      "            return True\n",
      "        else:\n",
      "            return False\n",
      "    \n",
      "    \n",
      "    def summarize_sdf(self, summarizer=L1_norm_col_summarizer):\n",
      "    \n",
      "        summary_data = summarizer(self[\"smatrix\"])\n",
      "        \n",
      "        if len(summary_data.shape) == 1:\n",
      "            _summary_data = summary_data\n",
      "        else:\n",
      "            assert len(summary_data.shape) == 2\n",
      "            assert summary_data.shape[0] == 1 or summary_data.shape[1] == 1\n",
      "            \n",
      "            if summary_data.shape[0] == 1:\n",
      "                _summary_data = np.array(summary_data)[0,:]\n",
      "            else:\n",
      "                _summary_data = np.array(summary_data)[:,0]\n",
      "            \n",
      "        \n",
      "        if _summary_data.shape[0] == self[\"smatrix\"].shape[0]:\n",
      "            return self._summerizer_class(summary_data = _summary_data,\n",
      "                                          summary_idx = self[\"row_idx\"],\n",
      "                                          sdf = self)\n",
      "            \n",
      "        if _summary_data.shape[0] == self[\"smatrix\"].shape[1]:\n",
      "            return self._summerizer_class(summary_data = _summary_data,\n",
      "                                          summary_idx = self[\"col_idx\"],\n",
      "                                          sdf = self)\n",
      "\n",
      "    \n",
      "    def select_columns(self, select_col = None):\n",
      "        \n",
      "        if select_col != None:\n",
      "            if isinstance(select_col, self._summerizer_class) and select_col._is_bool:\n",
      "                _select_col_idx = select_col._data\n",
      "            else:\n",
      "                _select_col_idx = select_col\n",
      "        else:\n",
      "            _select_col_idx = np.arange(len(self[\"col_idx\"]))\n",
      "        \n",
      "        new_col_idx = self[\"col_idx\"][_select_col_idx]\n",
      "        \n",
      "        new_smatrix = self[\"smatrix\"][:,_select_col_idx]\n",
      "        \n",
      "        return type(self)(smatrix = new_smatrix,\n",
      "                          col_idx = new_col_idx,\n",
      "                          row_idx = self[\"row_idx\"],\n",
      "                          summarizer = self[\"summarizer\"] if self._has_default_summarizer else None)\n",
      "    \n",
      "    \n",
      "    def select_rows(self, select_row = None):\n",
      "        if select_row != None:\n",
      "            if isinstance(select_row, self._summerizer_class) and select_row._is_bool:\n",
      "                _select_row_idx = select_row._data\n",
      "            else:\n",
      "                _select_row_idx = select_row\n",
      "        else:\n",
      "            _select_row_idx = np.arange(len(self[\"row_idx\"]))\n",
      "\n",
      "        new_row_idx = self[\"row_idx\"][_select_row_idx]\n",
      "        \n",
      "        new_smatrix = self[\"smatrix\"][_select_row_idx,:]\n",
      "        \n",
      "        return type(self)(smatrix = new_smatrix,\n",
      "                          col_idx = self[\"col_idx\"],\n",
      "                          row_idx = new_row_idx,\n",
      "                          summarizer = self[\"summarizer\"] if self._has_default_summarizer else None)\n",
      "    \n",
      "    \n",
      "    def sub_sdf(self, select_col = None, select_row = None):\n",
      "        return self.select_columns(select_col).select_rows(select_row)\n",
      "        \n",
      "    \n",
      "    def is_matched_col_shape(self, vec):\n",
      "        if isinstance(vec, list):\n",
      "            return len(vec) == self[\"smatrix\"].shape[1]\n",
      "        \n",
      "        if isinstance(vec, np.ndarray):\n",
      "            assert len(vec.shape) == 1\n",
      "            return vec.shape[0] == self[\"smatrix\"].shape[1]\n",
      "        \n",
      "    def is_matched_row_shape(self,vec):\n",
      "        if isinstance(vec, list):\n",
      "            return len(vec) == self[\"smatrix\"].shape[0]\n",
      "        \n",
      "        if isinstance(vec, np.ndarray):\n",
      "            assert len(vec.shape) == 1\n",
      "            return vec.shape[0] == self[\"smatrix\"].shape[0]\n",
      "            \n",
      "        \n",
      "    def is_col_vec(self,vec):\n",
      "        return self.is_matched_row_shape(vec)\n",
      "        \n",
      "        \n",
      "    def is_row_vec(self,vec):\n",
      "        return self.is_matched_col_shape(vec)\n",
      "        \n",
      "        \n",
      "    def to_pickle_file(self, output_file, with_prefix=True, close_after_dump=True):\n",
      "        \n",
      "        return write_pickle_file(obj=self, \n",
      "                                 write_file=output_file, \n",
      "                                 write_file_prefix=with_prefix, \n",
      "                                 close_after_write=close_after_dump)\n",
      "    \n",
      "    \n",
      "    \n",
      "        \n",
      "#        if isinstance(output_file, file):\n",
      "#            assert not output_file.closed\n",
      "#            pickle.dump(self, output_file)\n",
      "#            \n",
      "#            if close_after_dump:\n",
      "#                output_file.close()\n",
      "#                \n",
      "#        \n",
      "#        elif isinstance(output_file, (str,unicode)):\n",
      "#            #TODO: output_file includes filename and path \n",
      "#            with open(output_file, \"wb\") as wfile:\n",
      "#                pickle.dump(self, wfile)\n",
      "        \n",
      "    \n",
      "                "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sdf1 = vcr.vectorize_text(df=test_text_df.ix[:4],\n",
      "                           text_col=\"text\",\n",
      "                           idx_col=None, \n",
      "                           vect_gen=vcr.CountVectorizer, \n",
      "                           vect_gen_init_kwargs = unigram_vec_count_kwargs)\n",
      "\n",
      "sdf2 = vcr.vectorize_text(df=test_text_df.ix[4:],\n",
      "                           text_col=\"text\",\n",
      "                           idx_col=None, \n",
      "                           vect_gen=vcr.CountVectorizer, \n",
      "                           vect_gen_init_kwargs = unigram_vec_count_kwargs)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"// \".join(sdf1._col_idx)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u4eca// \u5929// \u597d// \u5b83// \u5f88// \u6068// \u611b// \u6211// \u6c23// \u721b\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"// \".join(sdf2._col_idx)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u4e00// \u4eca// \u5237// \u5929// \u5b50// \u5b83// \u5f88// \u611b// \u6211// \u65e5// \u6d17// \u7259// \u81c9// \u8870// \u904e\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"// \".join(np.intersect1d(sdf1._col_idx, sdf2._col_idx))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u4eca// \u5929// \u5b83// \u5f88// \u611b// \u6211\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"// \".join(np.setdiff1d(sdf1._col_idx, sdf2._col_idx))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u597d// \u6068// \u6c23// \u721b\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"// \".join(np.setdiff1d(sdf2._col_idx, sdf1._col_idx))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u4e00// \u5237// \u5b50// \u65e5// \u6d17// \u7259// \u81c9// \u8870// \u904e\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sdf1_only_col_idx = np.setdiff1d(sdf1._col_idx, sdf2._col_idx)\n",
      "intersect_col_idx = np.intersect1d(sdf1._col_idx, sdf2._col_idx)\n",
      "sdf2_only_col_idx = np.setdiff1d(sdf2._col_idx, sdf1._col_idx)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"sdf1_only_col_idx = \",sdf1_only_col_idx\n",
      "print \"intersect_col_idx = \",intersect_col_idx\n",
      "print \"sdf2_only_col_idx = \",sdf2_only_col_idx"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sdf1_only_col_idx =  [u'\\u597d' u'\\u6068' u'\\u6c23' u'\\u721b']\n",
        "intersect_col_idx =  [u'\\u4eca' u'\\u5929' u'\\u5b83' u'\\u5f88' u'\\u611b' u'\\u6211']\n",
        "sdf2_only_col_idx =  [u'\\u4e00' u'\\u5237' u'\\u5b50' u'\\u65e5' u'\\u6d17' u'\\u7259' u'\\u81c9'\n",
        " u'\\u8870' u'\\u904e']\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.r_[map(lambda xx:np.nonzero(sdf1._col_idx == xx)[0],intersect_col_idx)].T[0]\n",
      "print np.r_[map(lambda xx:np.nonzero(sdf2._col_idx == xx)[0],intersect_col_idx)].T[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0 1 3 4 6 7]\n",
        "[1 3 5 6 7 8]\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.r_[map(lambda xx:np.nonzero(sdf1._col_idx == xx)[0],intersect_col_idx)].T[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 80,
       "text": [
        "array([0, 1, 3, 4, 6, 7])"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = np.arange(1000)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit test[5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1000000 loops, best of 3: 178 ns per loop\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit test[test == 5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100000 loops, best of 3: 8.79 \u00b5s per loop\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit test[np.nonzero(test == 5)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100000 loops, best of 3: 14.2 \u00b5s per loop\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}